The results of all 3 optimisations can be seen in \cref{tab:Preconditioning} along with data for the non preconditioned system. All method had a fixed stopping criterion of $\lVert Mx-b \rVert_2/\lVert b \rVert_2 \leq 1e-6$. The 2016 swimmer model proved challenging to solve with over 150 more GMRES iterations needed to solve it. Both methods were aided by the use of an inital guess with the computation time being reduced by nearly 10\% as the initial iterations are replaced by quicker iterations using a smaller $\epsilon$ value. The attempt at re-scaling the lower augmented matrix was proven to increase the overall computation time, where the tighter clustered eigenvalues did not allow the method to converge any quicker. This was because the maximum and minimum eigenvalues became separated more, leading to a worse conditioned system overall. When we precondition the system we see a dramatic decrease in computation time, particularly with the 2016 swimmer case where the computation time drops by 80\%. The 203 swimmer case does not see such a significant drop, possibly due to the larger contribution that the stokeslet matrix $A$ has on the computation. We would expect to see that, for systems with more swimmers and the same number of quadrature points, the number of GMRES iterations needed to converge would stay approximately the same, and as such, larger systems could be tackled. Combinations of these methods may prove useful in reducing the calculation further, such as initial guesses for preconditioned systems, however due to the rapid decrease in the residual from the preconditioned system it is doubtful that it will provide any noticeable gain and the need to use the Heged{\"u}s trick involves another full matrix product. It might prove more useful in solving the reduced system inside the the preconditioner where the number of iterations can be quite large and the system is dominated more by the diagonal elements. A better way to reduce the computation time would be to improved the GMRES method though recycling the Krylov subspaces so as to solve repetitive linear systems \cite{Parks2006RecyclingSystems,Rostami2019FastBiofluids}. When solving the precondition we need to solve $P_A^{-1}$ twice for each iteration. The equivalent matrix for each solve remains constant with only the right-hand side changing. Instead of forming the Krylov subspace from scratch we can use some vectors from an existing Krylov subspace and construct a new Krylov subspace based on them for the new right hand side hence reducing the overall number of iterations needed for subsequent solves. This would also help with calculating the grand resistance matrix \cref{eq:GrandResistance} where multiple solutions need to be found for different right hand sides.



 It might prove more useful in solving the reduced system inside the the preconditioner where the number of iterations can be quite large and the system is dominated more by the diagonal elements. A better way to reduce the computation time would be to improved the GMRES method though recycling the Krylov subspaces so as to solve repetitive linear systems \cite{Parks2006RecyclingSystems,Rostami2019FastBiofluids}. When solving the precondition we need to solve $P_A^{-1}$ twice for each iteration. The equivalent matrix for each solve remains constant with only the right-hand side changing. Instead of forming the Krylov subspace from scratch we can use some vectors from an existing Krylov subspace and construct a new Krylov subspace based on them for the new right hand side hence reducing the overall number of iterations needed for subsequent solves. This would also help with calculating the grand resistance matrix \cref{eq:GrandResistance} where multiple solutions need to be found for different right hand sides.